<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 8.1.1">
<link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-round.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-round.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-round.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"wangjiezhe.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.25.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"atom-one-light","dark":"atom-one-dark-reasonable"},"prism":{"light":"prism","dark":"prism-okaidia"},"copy_button":{"enable":true,"style":"mac"},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":"disqusjs","storage":true,"lazyload":true,"nav":{"disqusjs":{"text":"Disqus","order":1},"giscus":{"text":"GitHub","order":2},"discussbot":{"text":"Telegram","order":3}},"activeClass":"disqusjs"},"stickytabs":false,"motion":{"enable":false,"async":true,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false,"style":"flat"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="使用vLLM部署PaddleOCR-VL模型，获得超过20倍的速度提升。">
<meta property="og:type" content="article">
<meta property="og:title" content="使用vLLM框架加速PaddleOCR-VL">
<meta property="og:url" content="https://wangjiezhe.github.io/posts/2025-11-04-Use-vLLM-to-Accelerate-PaddleOCR-VL/index.html">
<meta property="og:site_name" content="如鱼饮水">
<meta property="og:description" content="使用vLLM部署PaddleOCR-VL模型，获得超过20倍的速度提升。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://wangjiezhe.github.io/posts/2025-11-04-Use-vLLM-to-Accelerate-PaddleOCR-VL/k4H6LEdvpT.png">
<meta property="article:published_time" content="2025-11-04T09:15:22.000Z">
<meta property="article:modified_time" content="2025-11-04T09:15:22.000Z">
<meta property="article:author" content="西风冷香">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="OCR">
<meta property="article:tag" content="PaddleOCR-VL">
<meta property="article:tag" content="vLLM">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://wangjiezhe.github.io/posts/2025-11-04-Use-vLLM-to-Accelerate-PaddleOCR-VL/k4H6LEdvpT.png">


<link rel="canonical" href="https://wangjiezhe.github.io/posts/2025-11-04-Use-vLLM-to-Accelerate-PaddleOCR-VL/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://wangjiezhe.github.io/posts/2025-11-04-Use-vLLM-to-Accelerate-PaddleOCR-VL/","path":"/posts/2025-11-04-Use-vLLM-to-Accelerate-PaddleOCR-VL/","title":"使用vLLM框架加速PaddleOCR-VL"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>使用vLLM框架加速PaddleOCR-VL | 如鱼饮水</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-48537410-1"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"UA-48537410-1","only_pageview":false,"measure_protocol_api_secret":null}</script>
  <script src="/js/third-party/analytics/google-analytics.js" defer></script>

  <script src="/js/third-party/analytics/baidu-analytics.js" defer></script>
  <script async src="https://hm.baidu.com/hm.js?a51d31f349bffa6e3757f7d6fca0c47f"></script>


  <script data-pjax defer src='https://static.cloudflareinsights.com/beacon.min.js' data-cf-beacon='{&quot;token&quot;: &quot;4b43b380fa4e4d43a125ac710c29fb84&quot;}'></script>





  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
  <script src="https://cdn.jsdelivr.net/npm/@next-theme/pjax@0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous" defer></script>
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous" defer></script>
  <script src="https://cdn.jsdelivr.net/npm/lozad@1.16.0/dist/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous" defer></script>
<script src="/js/comments.js" defer></script><script src="/js/utils.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script><script src="/js/pjax.js" defer></script>

  <script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.5.0/dist/search.js" integrity="sha256-xFC6PJ82SL9b3WkGjFavNiA9gm5z6UBxWPiu4CYjptg=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdn.jsdelivr.net/npm/pdfobject@2.3.1/pdfobject.min.js","integrity":"sha256-jI72I8ZLVflVOisZIOaLvRew3tyvzeu6aZXFm7P7dEo="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js" defer></script>

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdn.jsdelivr.net/npm/mermaid@11.10.1/dist/mermaid.min.js","integrity":"sha256-BmQmdWDS8X2OTbrwELWK366LV6escyWhHHe0XCTU/Hk="}}</script>
  <script src="/js/third-party/tags/mermaid.js" defer></script>





  
  <script data-pjax async src="//bsz.wangjiezhe.com/js"></script>

  <script src="https://cdn.jsdelivr.net/npm/firebase@12.2.1/firebase-app-compat.js" integrity="sha256-d21UgtIcA6c6qwr8nWk6lxs/KrpbWhknQN7qBjWA2Kk=" crossorigin="anonymous" defer></script>
  <script src="https://cdn.jsdelivr.net/npm/firebase@12.2.1/firebase-firestore-compat.js" integrity="sha256-leHatffkFuVGIg7ABaA5BDsqsEUtktL4tftb3OdQfg0=" crossorigin="anonymous" defer></script>
  <script class="next-config" data-name="firestore" type="application/json">{"enable":true,"collection":"articles","apiKey":"AIzaSyD0AfWHrmFoKgV1x4srPQDN7rGpGclK7J4","projectId":"visitors-of-blog"}</script>
  <script src="/js/third-party/statistics/firestore.js" defer></script>



  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha256-UF1fgpAiu3tPJN/uCqEUHNe7pnr+QR0SQDNfgglgtcM=" crossorigin="anonymous">
  <script class="next-config" data-name="katex" type="application/json">{"copy_tex_js":{"url":"https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/copy-tex.min.js","integrity":"sha256-Us54+rSGDSTvIhKKUs4kygE2ipA0RXpWWh0/zLqw3bs="}}</script>
  <script src="/js/third-party/math/katex.js" defer></script>


  <script src="https://cdn.jsdelivr.net/npm/quicklink@3.0.1/dist/quicklink.umd.js" integrity="sha256-44BednzIpUeQJcY8qtLyarFu0UCCTbgmWOvaoehiFQQ=" crossorigin="anonymous" defer></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":false,"archive":false,"delay":true,"timeout":3000,"priority":true,"url":"https://wangjiezhe.github.io/posts/2025-11-04-Use-vLLM-to-Accelerate-PaddleOCR-VL/"}</script>
  <script src="/js/third-party/quicklink.js" defer></script>

  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="如鱼饮水" type="application/atom+xml">
<link rel="alternate" href="/rss2.xml" title="如鱼饮水" type="application/rss+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">如鱼饮水</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">冷暖自知</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-links"><a href="/links/" rel="section"><i class="fa fa-link fa-fw"></i>友链</a></li><li class="menu-item menu-item-fcircle"><a href="/fcircle/" rel="section"><i class="fa fa-user-group fa-fw"></i>朋友圈</a></li><li class="menu-item menu-item-tools"><a href="/tools/" rel="section"><i class="fa fa-rocket fa-fw"></i>工具</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E5%AE%89%E8%A3%85vLLM%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6"><span class="nav-text">1. 安装vLLM推理框架</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E8%B0%83%E7%94%A8vLLM%E6%8E%A8%E7%90%86%E6%9C%8D%E5%8A%A1"><span class="nav-text">2. 调用vLLM推理服务</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E9%80%9F%E5%BA%A6%E5%AF%B9%E6%AF%94"><span class="nav-text">3. 速度对比</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-%E5%9C%A8Kaggle%E4%B8%8A%E9%83%A8%E7%BD%B2"><span class="nav-text">4. 在Kaggle上部署</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="西风冷香"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">西风冷香</p>
  <div class="site-description" itemprop="description">某不知名机构不知名数学老师</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">95</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">20</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">143</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/wangjiezhe" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;wangjiezhe" rel="noopener me external nofollow noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:wangjiezhe@gmail.com" title="E-Mail → mailto:wangjiezhe@gmail.com" rel="noopener me external nofollow noreferrer" target="_blank"><i class="fa fa-envelope fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://x.com/wangjiezhe" title="Twitter → https:&#x2F;&#x2F;x.com&#x2F;wangjiezhe" rel="noopener me external nofollow noreferrer" target="_blank"><i class="fab fa-twitter fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://t.me/wangjiezhe" title="Telegram → https:&#x2F;&#x2F;t.me&#x2F;wangjiezhe" rel="noopener me external nofollow noreferrer" target="_blank"><i class="fab fa-telegram fa-fw"></i></a>
      </span>
  </div>
<div id="time-now">
  <canvas id="canvas" style="width:60%;">当前浏览器不支持canvas，请更换浏览器后再试</canvas>
</div>
<script>
(function(){

  var digit=
    [
      [
        [0,0,1,1,1,0,0],
        [0,1,1,0,1,1,0],
        [1,1,0,0,0,1,1],
        [1,1,0,0,0,1,1],
        [1,1,0,0,0,1,1],
        [1,1,0,0,0,1,1],
        [1,1,0,0,0,1,1],
        [1,1,0,0,0,1,1],
        [0,1,1,0,1,1,0],
        [0,0,1,1,1,0,0]
      ],//0
      [
        [0,0,0,1,1,0,0],
        [0,1,1,1,1,0,0],
        [0,0,0,1,1,0,0],
        [0,0,0,1,1,0,0],
        [0,0,0,1,1,0,0],
        [0,0,0,1,1,0,0],
        [0,0,0,1,1,0,0],
        [0,0,0,1,1,0,0],
        [0,0,0,1,1,0,0],
        [1,1,1,1,1,1,1]
      ],//1
      [
        [0,1,1,1,1,1,0],
        [1,1,0,0,0,1,1],
        [0,0,0,0,0,1,1],
        [0,0,0,0,1,1,0],
        [0,0,0,1,1,0,0],
        [0,0,1,1,0,0,0],
        [0,1,1,0,0,0,0],
        [1,1,0,0,0,0,0],
        [1,1,0,0,0,1,1],
        [1,1,1,1,1,1,1]
      ],//2
      [
        [1,1,1,1,1,1,1],
        [0,0,0,0,0,1,1],
        [0,0,0,0,1,1,0],
        [0,0,0,1,1,0,0],
        [0,0,1,1,1,0,0],
        [0,0,0,0,1,1,0],
        [0,0,0,0,0,1,1],
        [0,0,0,0,0,1,1],
        [1,1,0,0,0,1,1],
        [0,1,1,1,1,1,0]
      ],//3
      [
        [0,0,0,0,1,1,0],
        [0,0,0,1,1,1,0],
        [0,0,1,1,1,1,0],
        [0,1,1,0,1,1,0],
        [1,1,0,0,1,1,0],
        [1,1,1,1,1,1,1],
        [0,0,0,0,1,1,0],
        [0,0,0,0,1,1,0],
        [0,0,0,0,1,1,0],
        [0,0,0,1,1,1,1]
      ],//4
      [
        [1,1,1,1,1,1,1],
        [1,1,0,0,0,0,0],
        [1,1,0,0,0,0,0],
        [1,1,1,1,1,1,0],
        [0,0,0,0,0,1,1],
        [0,0,0,0,0,1,1],
        [0,0,0,0,0,1,1],
        [0,0,0,0,0,1,1],
        [1,1,0,0,0,1,1],
        [0,1,1,1,1,1,0]
      ],//5
      [
        [0,0,0,0,1,1,0],
        [0,0,1,1,0,0,0],
        [0,1,1,0,0,0,0],
        [1,1,0,0,0,0,0],
        [1,1,0,1,1,1,0],
        [1,1,0,0,0,1,1],
        [1,1,0,0,0,1,1],
        [1,1,0,0,0,1,1],
        [1,1,0,0,0,1,1],
        [0,1,1,1,1,1,0]
      ],//6
      [
        [1,1,1,1,1,1,1],
        [1,1,0,0,0,1,1],
        [0,0,0,0,1,1,0],
        [0,0,0,0,1,1,0],
        [0,0,0,1,1,0,0],
        [0,0,0,1,1,0,0],
        [0,0,1,1,0,0,0],
        [0,0,1,1,0,0,0],
        [0,0,1,1,0,0,0],
        [0,0,1,1,0,0,0]
      ],//7
      [
        [0,1,1,1,1,1,0],
        [1,1,0,0,0,1,1],
        [1,1,0,0,0,1,1],
        [1,1,0,0,0,1,1],
        [0,1,1,1,1,1,0],
        [1,1,0,0,0,1,1],
        [1,1,0,0,0,1,1],
        [1,1,0,0,0,1,1],
        [1,1,0,0,0,1,1],
        [0,1,1,1,1,1,0]
      ],//8
      [
        [0,1,1,1,1,1,0],
        [1,1,0,0,0,1,1],
        [1,1,0,0,0,1,1],
        [1,1,0,0,0,1,1],
        [0,1,1,1,0,1,1],
        [0,0,0,0,0,1,1],
        [0,0,0,0,0,1,1],
        [0,0,0,0,1,1,0],
        [0,0,0,1,1,0,0],
        [0,1,1,0,0,0,0]
      ],//9
      [
        [0,0,0,0,0,0,0],
        [0,0,1,1,1,0,0],
        [0,0,1,1,1,0,0],
        [0,0,1,1,1,0,0],
        [0,0,0,0,0,0,0],
        [0,0,0,0,0,0,0],
        [0,0,1,1,1,0,0],
        [0,0,1,1,1,0,0],
        [0,0,1,1,1,0,0],
        [0,0,0,0,0,0,0]
      ]//:
    ];

  var canvas = document.getElementById('canvas');

  if(canvas.getContext){
    var cxt = canvas.getContext('2d');
    //声明canvas的宽高
    var H = 100,W = 700;
    canvas.height = H;
    canvas.width = W;
    cxt.fillStyle = '#f00';
    cxt.fillRect(10,10,50,50);

    //存储时间数据
    var data = [];
    //存储运动的小球
    var balls = [];
    //设置粒子半径
    var R = canvas.height/20-1;
    (function(){
      var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
      //存储时间数字，由十位小时、个位小时、冒号、十位分钟、个位分钟、冒号、十位秒钟、个位秒钟这7个数字组成
      data.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
    })();

    /*生成点阵数字*/
    function renderDigit(index,num){
      for(var i = 0; i < digit[num].length; i++){
        for(var j = 0; j < digit[num][i].length; j++){
          if(digit[num][i][j] == 1){
            cxt.beginPath();
            cxt.arc(14*(R+2)*index + j*2*(R+1)+(R+1),i*2*(R+1)+(R+1),R,0,2*Math.PI);
            cxt.closePath();
            cxt.fill();
          }
        }
      }
    }

    /*更新时钟*/
    function updateDigitTime(){
      var changeNumArray = [];
      var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
      var NewData = [];
      NewData.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
      for(var i = data.length-1; i >=0 ; i--){
        //时间发生变化
        if(NewData[i] !== data[i]){
          //将变化的数字值和在data数组中的索引存储在changeNumArray数组中
          changeNumArray.push(i+'_'+(Number(data[i])+1)%10);
        }
      }
      //增加小球
      for(var i = 0; i< changeNumArray.length; i++){
        addBalls.apply(this,changeNumArray[i].split('_'));
      }
      data = NewData.concat();
    }

    /*更新小球状态*/
    function updateBalls(){
      for(var i = 0; i < balls.length; i++){
        balls[i].stepY += balls[i].disY;
        balls[i].x += balls[i].stepX;
        balls[i].y += balls[i].stepY;
        if(balls[i].x > W + R || balls[i].y > H + R){
          balls.splice(i,1);
          i--;
        }
      }
    }

    /*增加要运动的小球*/
    function addBalls(index,num){
      var numArray = [1,2,3];
      var colorArray =  ["#3BE","#09C","#A6C","#93C","#9C0","#690","#FB3","#F80","#F44","#C00"];
      for(var i = 0; i < digit[num].length; i++){
        for(var j = 0; j < digit[num][i].length; j++){
          if(digit[num][i][j] == 1){
            var ball = {
              x:14*(R+2)*index + j*2*(R+1)+(R+1),
              y:i*2*(R+1)+(R+1),
              stepX:Math.floor(Math.random() * 4 -2),
              stepY:-2*numArray[Math.floor(Math.random()*numArray.length)],
              color:colorArray[Math.floor(Math.random()*colorArray.length)],
              disY:1
            };
            balls.push(ball);
          }
        }
      }
    }

    /*渲染*/
    function render(){
      //重置画布宽度，达到清空画布的效果
      canvas.height = 100;
      //获取颜色，支持暗色模式
      var clockColor = getComputedStyle(document.documentElement).getPropertyValue('--text-color');
      cxt.fillStyle = clockColor;
      //渲染时钟
      for(var i = 0; i < data.length; i++){
        renderDigit(i,data[i]);
      }
      //渲染小球
      for(var i = 0; i < balls.length; i++){
        cxt.beginPath();
        cxt.arc(balls[i].x,balls[i].y,R,0,2*Math.PI);
        cxt.fillStyle = balls[i].color;
        cxt.closePath();
        cxt.fill();
      }
    }

    clearInterval(oTimer);
    var oTimer = setInterval(function(){
      //更新时钟
      updateDigitTime();
      //更新小球状态
      updateBalls();
      //渲染
      render();
    },50);
  }

})();
</script>

<div id="site-days"></div>
<script>
  function show_date_time() {
    window.setTimeout("show_date_time()", 1000);
    BirthDay = new Date("2014/01/10 13:29:55");
    today = new Date();
    timeold = (today.getTime() - BirthDay.getTime());
    sectimeold = timeold / 1000;
    secondsold = Math.floor(sectimeold);
    msPerDay = 24 * 60 * 60 * 1000;
    e_daysold = timeold / msPerDay;
    daysold = Math.floor(e_daysold);
    e_hrsold = (e_daysold - daysold) * 24;
    hrsold = setzero(Math.floor(e_hrsold));
    e_minsold = (e_hrsold - hrsold) * 60;
    minsold = setzero(Math.floor((e_hrsold - hrsold) * 60));
    seconds = setzero(Math.floor((e_minsold - minsold) * 60));
    document.getElementById('site-days').innerHTML = "已运行" + daysold + "天" + hrsold + "小时" + minsold + "分" + seconds + "秒";
  }

  function setzero(i) {
    if (i < 10) {
      i = "0" + i
    }
    return i;
  }

  show_date_time();
</script>

        </div>
      </div>
    </div>

    
        <div class="pjax">
        <div class="sidebar-inner sidebar-post-related">
          <div class="animated">
              <div class="links-of-blogroll-title"><i class="fa fa-signs-post fa-fw"></i>
    相关文章
  </div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <a class="popular-posts-link" href="/posts/2025-11-03-Compare-PaddleOCR-VL-with-PaddleOCR/" rel="bookmark">
        <time class="popular-posts-time">2025-11-03</time>
        <br>
      关于PaddleOCR-VL和PaddleOCR对数学类书籍识别的对比
      </a>
    </li>
    <li class="popular-posts-item">
      <a class="popular-posts-link" href="/posts/2025-10-26-Deploy-DeepSeek-OCR-on-Kaggle/" rel="bookmark">
        <time class="popular-posts-time">2025-10-26</time>
        <br>
      白嫖Kaggle平台部署DeepSeek-OCR
      </a>
    </li>
  </ul>

          </div>
        </div>
        </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wangjiezhe.github.io/posts/2025-11-04-Use-vLLM-to-Accelerate-PaddleOCR-VL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="西风冷香">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="如鱼饮水">
      <meta itemprop="description" content="某不知名机构不知名数学老师">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="使用vLLM框架加速PaddleOCR-VL | 如鱼饮水">
      <meta itemprop="description" content="使用vLLM部署PaddleOCR-VL模型，获得超过20倍的速度提升。">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          使用vLLM框架加速PaddleOCR-VL
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-11-04 17:15:22" itemprop="dateCreated datePublished" datetime="2025-11-04T17:15:22+08:00">2025-11-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.1k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>10 分钟</span>
    </span>
</div>

            <div class="post-description">使用vLLM部署PaddleOCR-VL模型，获得超过20倍的速度提升。</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p><a href="/posts/2025-11-02-Try-PaddleOCR-VL/">之前</a>直接使用PaddlePaddle进行PaddleOCR-VL的推理，优点是安装相对简单，但缺点是速度太慢了，推理速度只有之前PaddleOCR的40%，这已经比DeepSeek-OCR快不了多少了。这个速度识别几本书还行，多了的话速度根本不够。</p>
<p>造成速度慢的主要原因是PaddleOCR-VL模型在不使用推理框架的时候，只支持使用 <code>batch_size=1</code> 进行推理，因此GPU根本跑不起来。</p>
<p>PaddleOCR-VL是支持使用vLLM框架进行加速的。之前没有使用，主要是在安装的时候发现需要装特定版本的 <code>flash-attn</code>，于是就放弃了。</p>
<div class="note info"><p>编译安装 <code>flash-attn</code> 需要的内存极其恐怖。如果不做任何配置的话，编译过程中 <code>ninja</code> 会自动根据CPU内核数量开启并行编译，而 <code>flash-attn</code> 在使用nvcc编译的时候又默认开启 <code>sm_80</code>、<code>sm_90</code>、<code>sm_100</code>、<code>sm_120</code> 四个编译目标，因此在我的电脑上，实际会同时运行 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>32</mn><mo>×</mo><mn>4</mn><mo>=</mo><mn>128</mn></mrow><annotation encoding="application/x-tex">32\times 4=128</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">32</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">128</span></span></span></span> 个进程进行编译。</p>
<p>这样的话，即使我给WSL分配了50G的内存和75G的交换文件，也很快就被爆掉了。</p>
<p>之前在系统里安装这个包的时候，我是把 <code>MAX_JOBS</code> 设为3，然后修改源代码只开启 <code>sm_80</code>、<code>sm_89</code> 两个编译目标，这样只有6个进程同时进行编译，才不会爆内存。</p>
<p>不过如此设置的话，编译速度也就很感人了，编译一次就要超过1小时。</p>
<p>作为对比，下面是我的电脑上常用的「大」软件的编译时间：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># qlop -cmv sci-ml/caffe2-2.9.0 sci-ml/flash-attention-2.8.3 sys-devel/gcc-14.3.0 llvm-core/llvm-21.1.4 llvm-core/clang-21.1.4 dev-lang/rust-1.91.0</span></span><br><span class="line"><span class="attribute">dev</span>-lang/rust-<span class="number">1</span>.<span class="number">91</span>.<span class="number">0</span>: <span class="number">21</span>′<span class="number">57</span>″ average for <span class="number">1</span> merge</span><br><span class="line"><span class="attribute">llvm</span>-core/clang-<span class="number">21</span>.<span class="number">1</span>.<span class="number">4</span>: <span class="number">21</span>′<span class="number">49</span>″ average for <span class="number">1</span> merge</span><br><span class="line"><span class="attribute">llvm</span>-core/llvm-<span class="number">21</span>.<span class="number">1</span>.<span class="number">4</span>: <span class="number">28</span>′<span class="number">42</span>″ average for <span class="number">1</span> merge</span><br><span class="line"><span class="attribute">sci</span>-ml/caffe2-<span class="number">2</span>.<span class="number">9</span>.<span class="number">0</span>: <span class="number">24</span>′<span class="number">25</span>″ average for <span class="number">1</span> merge</span><br><span class="line"><span class="attribute">sci</span>-ml/flash-attention-<span class="number">2</span>.<span class="number">8</span>.<span class="number">3</span>: <span class="number">1</span>:<span class="number">11</span>:<span class="number">42</span> average for <span class="number">1</span> merge</span><br><span class="line"><span class="attribute">sys</span>-devel/gcc-<span class="number">14</span>.<span class="number">3</span>.<span class="number">0</span>: <span class="number">22</span>′<span class="number">30</span>″ average for <span class="number">1</span> merge</span><br><span class="line"><span class="attribute">total</span>: <span class="number">3</span>:<span class="number">11</span>:<span class="number">05</span> for <span class="number">6</span> merges</span><br></pre></td></tr></table></figure>
<p>可能也就只有之前编译TensorFlow的时间比它长了。</p>
</div>
<p>好在，最新的文档给出了 <code>flash-attn</code> 的预编译包的<a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/mjun0812/flash-attention-prebuild-wheels">仓库</a>，里面有各个版本的编译好的包可以直接使用，因此就可以配置vLLM了。</p>
<h2 id="1-安装vLLM推理框架"><a class="header-anchor" href="#1-安装vLLM推理框架"></a>1. 安装vLLM推理框架</h2>
<p>按照官方提示，</p>
<blockquote>
<p>由于推理加速框架可能与飞桨框架存在依赖冲突，建议在虚拟环境中安装。</p>
</blockquote>
<p>我看了一下，主要是PaddlePaddle和vLLM依赖的PyTorch对于一系列nvidia包的不同（<code>paddlepaddle-gpu==3.2.0</code> 依赖12.9版本的CUDA，而 <code>vllm==0.10.2</code> 依赖 <code>pytorch==2.8.0</code> 及12.8版本的CUDA）。</p>
<p>所以新建一个虚拟环境，并安装vLLM推理框架：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">uv venv --seed -p python3.12 .venv_vllm</span><br><span class="line">VIRTUAL_ENV=.venv_vllm uv pip install <span class="string">&quot;paddleocr[doc-parser]&quot;</span></span><br><span class="line">VIRTUAL_ENV=.venv_vllm uv pip install https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu129torch2.8-cp312-cp312-linux_x86_64.whl</span><br><span class="line">VIRTUAL_ENV=.venv_vllm uv run paddleocr install_genai_server_deps vllm</span><br></pre></td></tr></table></figure>
<div class="note danger"><p>注意：</p>
<ul>
<li>要先安装预编译的 <code>flash-attn</code> 包，否则直接运行安装vLLM框架的命令会报错。</li>
<li>要根据Python版本、Pytorch版本（目前版本的vLLM依赖的是2.8）来选择对应的 <code>flash-attn</code> 包。具体的链接在上面仓库的主页可以找到。</li>
</ul>
</div>
<div class="note success"><p>可选项：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">VIRTUAL_ENV=.venv_vllm uv pip install flashinfer-python flashinfer-cubin</span><br><span class="line">VIRTUAL_ENV=.venv_vllm uv pip install flashinfer-jit-cache --default-index https://flashinfer.ai/whl/cu129</span><br></pre></td></tr></table></figure>
<p>貌似有一点点速度提升？</p>
</div>
<p>然后就可以启动vLLM服务了：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">VIRTUAL_ENV=.venv_vllm uv run paddleocr genai_server \</span><br><span class="line">  --model_name PaddleOCR-VL-0.9B \</span><br><span class="line">  --backend vllm \</span><br><span class="line">  --port 8118 \</span><br><span class="line">  --backend_config &lt;(<span class="built_in">echo</span> -e <span class="string">&#x27;gpu-memory-utilization: 0.8\nmax-model-len: 8192&#x27;</span>)</span><br></pre></td></tr></table></figure>
<div class="note primary"><p>这里<strong>务必</strong>要根据自己的显卡对vLLM服务参数进行调整。作为参考，我的显卡是RTX4060，显存大小是8G。</p>
<p>从PaddleX的<a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/PaddlePaddle/PaddleX/blob/802629c2f7efd500d782139943714974edfa92b9/paddlex/inference/genai/configs/paddleocr_vl_09b.py#L24">配置文件</a>可以看到，默认传给vLLM的参数为：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">trust-remote-code:</span> <span class="literal">True</span></span><br><span class="line"><span class="attr">gpu-memory-utilization:</span> <span class="number">0.5</span></span><br><span class="line"><span class="attr">max-model-len:</span> <span class="number">16384</span></span><br><span class="line"><span class="attr">max-num-batched-tokes:</span> <span class="number">131072</span></span><br><span class="line"><span class="attr">api-server-count:</span> <span class="number">4</span></span><br></pre></td></tr></table></figure>
<p>其中必须调整的参数：</p>
<p><code>gpu_memory_utilization</code> 是vLLM可以占用的显存比例，如果是默认的0.5即50%，由于我的笔记本电脑显存只有8G，使用一半的话就只有4G了，这是肯定不够的，因此就直接报错了。</p>
<p>根据之前的经验，在使用PaddlePaddle进行推理的时候就需要5~6G的显存。因此我给vLLM分配了80%的显存，这样就足够了。</p>
<p>另外，在开启独显直连的情况下，即使不进行什么复杂任务，显存也要用掉0.8~1.2G。计算可用显存的时候要把这部分刨去。</p>
<p><code>max_model_len</code> 是模型的上下文长度。默认值对我来说太大了，直接就报错说显存不够。</p>
<p>在没有运行其它占用显存的程序的时候，把 <code>max_model_len</code> 设为 <code>8192</code> 是可以运行的。但我也遇到过一次启动报错的情况，因此可以把它再调小一些。</p>
<p>不过，这个值也不能太小了，至少是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4096</mn><mo>+</mo><mn>14</mn><mo>=</mo><mn>4110</mn></mrow><annotation encoding="application/x-tex">4096+14=4110</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4096</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">14</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">4110</span></span></span></span>。因为输入要用掉14个tokens，默认的最大输出是4096个tokens，因此至少要不小于这两个加起来的数量，否则推理的时候就会报错。</p>
<div class="note success"><p>实测在我的电脑上最低可用的配置为</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">gpu-memory-utilization:</span> <span class="number">0.79</span></span><br><span class="line"><span class="attr">max-model-len:</span> <span class="number">4110</span></span><br></pre></td></tr></table></figure></div>
<div class="note warning"><p>不过还是尽可能把<code>max-model-len</code>拉大一些比较好，否则实测在识别一些大型表格的时候会漏掉一些部分。</p>
</div></div>
<p>当屏幕出现 <code>&quot;GET /health HTTP/1.1&quot; 200 OK</code> 的字样时就说明vLLM服务启动成功了。</p>
<div class="note warning"><p>在vLLM服务的启动过程中，占用的显存会超过8G，如图</p>
<p><img data-src="k4H6LEdvpT.png" alt="" /></p>
<p>不过很快就回落了，最终在推理的时候也不需要借用内存，因此不会影响推理速度。</p>
</div>
<h2 id="2-调用vLLM推理服务"><a class="header-anchor" href="#2-调用vLLM推理服务"></a>2. 调用vLLM推理服务</h2>
<p>在另一个终端可以直接使用命令行进行调用：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">uv run paddleocr doc_parser \</span><br><span class="line">  --input input/test.pdf \</span><br><span class="line">  --save_path output \</span><br><span class="line">  --vl_rec_backend vllm-server \</span><br><span class="line">  --vl_rec_server_url http://localhost:8118/v1</span><br></pre></td></tr></table></figure>
<p>也可以使用Python进行调用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">pipeline = PaddleOCRVL(</span><br><span class="line">    use_doc_orientation_classify=<span class="literal">False</span>,</span><br><span class="line">    use_doc_unwarping=<span class="literal">False</span>,</span><br><span class="line">    use_chart_recognition=<span class="literal">False</span>,</span><br><span class="line">    vl_rec_backend=<span class="string">&quot;vllm-server&quot;</span>,</span><br><span class="line">    vl_rec_server_url=<span class="string">&quot;http://localhost:8118/v1&quot;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>后续的使用方法就和<a href="/posts/2025-11-02-Try-PaddleOCR-VL/">之前</a>一样了。</p>
<h2 id="3-速度对比"><a class="header-anchor" href="#3-速度对比"></a>3. 速度对比</h2>
<p>使用vLLM会带来巨大（<strong>超过20倍</strong>）的速度提升。在我的电脑上，跑完8本小蓝本，只需要27分41秒（均衡模式）。在推理过程中，显卡基本保持在80W的功率。</p>
<p>作为对比，在Kaggle上使用 <code>GPU T4x2</code>，并开启双卡双进程编译，需要5小时40分。</p>
<p>之前在本地运行的时候没有总计时，但是基本每本书都需要1小时以上的时间，其中最厚的《三角形与四边形》甚至需要将近两个小时。</p>
<h2 id="4-在Kaggle上部署"><a class="header-anchor" href="#4-在Kaggle上部署"></a>4. 在Kaggle上部署</h2>
<p>在Kaggle上部署的方法和在本地部署是一致的，显卡选择 <code>GPU T4x2</code>，只是需要调整一下 <code>flash-attn</code> 预编译包的版本。</p>
<p>不过，参考<a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.paddleocr.ai/latest/version3.x/pipeline_usage/PaddleOCR-VL.html#paddleocr-vl_1">官方文档</a>：</p>
<table>
<thead>
<tr>
<th style="text-align:center">推理方式</th>
<th style="text-align:center">支持的 GPU Compute Capability</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">vLLM</td>
<td style="text-align:center">≥ 8 （RTX 3060，RTX 5070，A10，A100, ...）<br/>7 ≤ GPU Compute Capability &lt; 8 （T4，V100，...）支持运行，<br/>但可能出现请求超时、OOM 等异常情况，不推荐使用</td>
</tr>
</tbody>
</table>
<p>实测也确实如此。在Kaggle上部署之后，简单调用识别个图片还是没问题的，一旦涉及到多页PDF就经常报错。</p>
<p>而且此时在Kaggle上的推理速度还不到本地（RTX4060 8G）的一半，因此完全没有使用的必要了。</p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>西风冷香
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://wangjiezhe.github.io/posts/2025-11-04-Use-vLLM-to-Accelerate-PaddleOCR-VL/" title="使用vLLM框架加速PaddleOCR-VL">https://wangjiezhe.github.io/posts/2025-11-04-Use-vLLM-to-Accelerate-PaddleOCR-VL/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener external nofollow noreferrer" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="followme">
  <span>欢迎关注我的其它发布渠道</span>

  <div class="social-list">

      <div class="social-item">
          <span class="social-link">
            <span class="icon">
              <i class="fab fa-weixin"></i>
            </span>

            <span class="label">WeChat</span>
          </span>

          <img class="social-item-img" src="/images/wechat_channel.jpg">
      </div>

      <div class="social-item">
          <a target="_blank" class="social-link" href="/atom.xml">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>

            <span class="label">RSS</span>
          </a>
      </div>
  </div>
</div>

          <div class="post-tags">
              <a href="/tags/AI/" rel="tag"><i class="fa fa-tag"></i> AI</a>
              <a href="/tags/OCR/" rel="tag"><i class="fa fa-tag"></i> OCR</a>
              <a href="/tags/PaddleOCR-VL/" rel="tag"><i class="fa fa-tag"></i> PaddleOCR-VL</a>
              <a href="/tags/vLLM/" rel="tag"><i class="fa fa-tag"></i> vLLM</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/posts/2025-11-03-Compare-PaddleOCR-VL-with-PaddleOCR/" rel="prev" title="关于PaddleOCR-VL和PaddleOCR对数学类书籍识别的对比">
                  <i class="fa fa-angle-left"></i> 关于PaddleOCR-VL和PaddleOCR对数学类书籍识别的对比
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/posts/2025-11-05-LuaLaTeX-xkanjiskip/" rel="next" title="在使用LuaLaTeX时控制中英文字符的间距">
                  在使用LuaLaTeX时控制中英文字符的间距 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






      <div class="tabs tabs-comment">
        <ul class="nav-tabs">
            <li class="tab"><a href="#comment-disqusjs">Disqus</a></li>
            <li class="tab"><a href="#comment-giscus">GitHub</a></li>
        </ul>
        <div class="tab-content">
            <div class="tab-pane disqusjs" id="comment-disqusjs">
              
  <div class="comments disqusjs-container">
    <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
  </div>
  
            </div>
            <div class="tab-pane giscus" id="comment-giscus">
              
  
  <div class="comments giscus-container">
  </div>
  
  
            </div>
        </div>
      </div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener external nofollow noreferrer" target="_blank">冀ICP备2024063721号-1 </a>
      <img src="/images/gongan.png" alt=""><a href="https://beian.mps.gov.cn/#/query/webSearch?code=13090202000716" rel="noopener external nofollow noreferrer" target="_blank">冀公网安备13090202000716号 </a>
  </div>
  <div class="copyright">
    &copy; 2014 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">西风冷香</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">341k</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener external nofollow noreferrer" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener external nofollow noreferrer" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

<div class="blog-links">
    <span class="post-meta-item moe">
      <span>
        <img src="/images/icp-moe.png" style="width:auto;height:16px;" alt="">
      </span>
      <span><a href="https://icp.gov.moe/?keyword=20248191" rel="noopener external nofollow noreferrer" target="_blank">萌ICP备20248191号</a>
      </span>
    </span>
    <span class="post-meta-item travel-moe">
      <span><a href="https://travel.moe/go.html?travel=on" rel="noopener external nofollow noreferrer" target="_blank"><img src="/images/travel-moe.png" style="width:auto;height:18px" title="异次元之旅-跃迁-我们一起去萌站成员的星球旅行吧！"> 异次元之旅🚀</a>
      </span>
    </span>
    <span class="post-meta-item foreverblog"><a href="https://www.foreverblog.cn/blog/2092.html" rel="noopener external nofollow noreferrer" target="_blank"><img src="/images/foreverblog.png" style="width:auto;height:16px;" alt="Forever Blog"></a>
    </span>
    <span class="post-meta-item wormhole"><a href="https://www.foreverblog.cn/go.html" rel="noopener external nofollow noreferrer" target="_blank"><img src="/images/wormhole.gif" style="width:auto;height:24px;" alt="" title="穿梭虫洞-随机访问十年之约友链博客"></a>
    </span>
    <span class="post-meta-item travelling"><a href="https://www.travellings.cn/go.html" rel="noopener external nofollow noreferrer" target="_blank"><img src="/images/travelling.png" alt="开往-友链接力" height="18"></a>
    </span>
  
</div>

<script>
function checkWebp(callback) {
  var img = new Image();
  img.onload = function () { callback((img.width > 0) && (img.height > 0)); };
  img.onerror = function () { callback(false); };
  img.src = 'data:image/webp;base64,UklGRiIAAABXRUJQVlA4IBYAAAAwAQCdASoBAAEADsD+JaQAA3AAAAAA';
}
function showImage(useWebp) {
  var imgs = [].slice.call(document.querySelectorAll('img'));
  imgs.forEach(function (e) {
    if ((useWebp) && !e.classList.contains('nowebp')) {
      var src = e.getAttribute('data-src')
      if (src !== null) {
        src = src.replace(/\.jpg$/, '.webp').replace(/\.jpeg$/, '.webp').replace(/\.png$/, '.webp').replace(/\.gif$/, '.webp');
        e.setAttribute('data-src', src);
      }
      src = e.getAttribute('src')
      if (src !== null) {
        src = src.replace(/\.jpg$/, '.webp').replace(/\.jpeg$/, '.webp').replace(/\.png$/, '.webp').replace(/\.gif$/, '.webp');
        e.setAttribute('src', src);
      }
    }
  });
}
</script>
<script data-pjax async>
checkWebp(showImage);
</script>


    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>
<script class="next-config" data-name="giscus" type="application/json">{"enable":true,"repo":"wangjiezhe/wangjiezhe.github.io","repo_id":"MDEwOlJlcG9zaXRvcnkxNTc4OTE0Ng==","category":"Announcements","category_id":"DIC_kwDOAPDsWs4Cdwtf","mapping":"og:title","strict":1,"reactions_enabled":1,"emit_metadata":1,"theme":"https://wangjiezhe.com/css/giscus.min.css","lang":"zh-CN","crossorigin":"anonymous","input_position":"top","loading":"lazy"}</script>

<script>
document.addEventListener('page:loaded', () => {
  if (!CONFIG.page.comments) return;

  NexT.utils.loadComments('.giscus-container')
    .then(() => NexT.utils.getScript('https://giscus.app/client.js', {
      attributes: {
        async                   : true,
        crossOrigin             : 'anonymous',
        'data-repo'             : CONFIG.giscus.repo,
        'data-repo-id'          : CONFIG.giscus.repo_id,
        'data-category'         : CONFIG.giscus.category,
        'data-category-id'      : CONFIG.giscus.category_id,
        'data-mapping'          : CONFIG.giscus.mapping,
        'data-strict'           : CONFIG.giscus.strict,
        'data-reactions-enabled': CONFIG.giscus.reactions_enabled,
        'data-emit-metadata'    : CONFIG.giscus.emit_metadata,
        'data-theme'            : CONFIG.giscus.theme,
        'data-lang'             : CONFIG.giscus.lang,
        'data-input-position'   : CONFIG.giscus.input_position,
        'data-loading'          : CONFIG.giscus.loading
      },
      parentNode: document.querySelector('.giscus-container')
    }));
});
</script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/disqusjs@3.1.0/dist/browser/styles/disqusjs.css" integrity="sha256-E4RzceSomICFY1PT/yDQrN8DsLSwdScDEiQAevHabp0=" crossorigin="anonymous">

<script class="next-config" data-name="disqusjs" type="application/json">{"enable":true,"api":"https://disqusjs.wangjiezhe.com/","apikey":"ENTX2OPfWXIYJpFIZ1WVpYt4F0Ri0PLUELMOCbM8HHIX9C9BqEbkBZWmK7lqKj7F","shortname":"wangjiezhe","js":{"url":"https://cdn.jsdelivr.net/npm/disqusjs@3.1.0/dist/browser/disqusjs.es2015.umd.min.js","integrity":"sha256-gdbBT62HLzqWTnXQED3WQL/ItFCuWsA5gd6dM/wgdiE="}}</script>
<script src="/js/third-party/comments/disqusjs.js" defer></script>



  <script async src="/js/cursor/fireworks.min.js" integrity="sha256-NVjeK0/Qni9W+mCWpzpw6IZTieyhLZJ5Kj4hdFjqSQc=" crossorigin="anonymous"></script>



<script src="https://cdn.jsdelivr.net/npm/@wangjiezhe/live2d-widget@^3.1.7/lib/L2Dwidget.min.js"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"https://cdn.jsdelivr.net/npm/live2d-widget-model-mikoto@1.0.0/assets/mikoto.model.json"},"display":{"position":"left"},"mobile":{"show":false},"log":false});</script></body>
</html>
